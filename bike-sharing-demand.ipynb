{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project Overview\n",
    "- 강의명 : 2022년 K-디지털 직업훈련(Training) 사업 - AI데이터플랫폼을 활용한 빅데이터 분석전문가 과정\n",
    "- 교과목명 : 빅데이터 분석 및 시각화, AI개발 기초, 인공지능 프로그래밍\n",
    "- 프로젝트 주제 : 캐글 대회 Bike Sharing Demand 데이터를 활용한 수요 예측 대회\n",
    "- 프로젝트 마감일 : 2022년 7월 19일 화요일\n",
    "- 수강생명 : 홍승기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.\n",
    "\n",
    "The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- https://www.kaggle.com/code/viveksrinivasan/eda-ensemble-model-top-10-percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fields\n",
    "- datetime - hourly date + timestamp  \n",
    "- season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "- holiday - whether the day is considered a holiday\n",
    "- workingday - whether the day is neither a weekend nor holiday\n",
    "- weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "- temp - temperature in Celsius\n",
    "- atemp - \"feels like\" temperature in Celsius\n",
    "- humidity - relative humidity\n",
    "- windspeed - wind speed\n",
    "- casual - number of non-registered user rentals initiated\n",
    "- registered - number of registered user rentals initiated\n",
    "- count - number of total rentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 01. Load Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd   # Data processing\n",
    "import numpy as np    # Numerical operation\n",
    "import matplotlib as mpl           # Data visualization\n",
    "import matplotlib.pyplot as plt    # Data visualization\n",
    "import seaborn as sns              # Data visualization\n",
    "import sklearn   # Machine Learning\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Version check\n",
    "print(\"pandas version : \", pd.__version__)\n",
    "print(\"numpy version : \", np.__version__)\n",
    "print(\"matplotlib version : \", mpl.__version__)\n",
    "print(\"seaborn version : \", sns.__version__)\n",
    "print(\"sklearn version : \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02. Read The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/kaggle/input/bike-sharing-demand/'\n",
    "train_data = pd.read_csv(DATA_PATH + 'train.csv')   # Train dataset\n",
    "test_data = pd.read_csv(DATA_PATH + 'test.csv')     # Test dataset\n",
    "submission_data = pd.read_csv(DATA_PATH + 'sampleSubmission.csv')   # submission dataset\n",
    "\n",
    "train_data.shape, test_data.shape, submission_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samlpe of First Five Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test dataset, there are columns\"casual\", \"registered\" that do not exist in addition to the count column. Our goal is to predict the frequency of the count column. Therefore, we will drop the \"casual\" and \"registered\" columns from the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information of the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data.info())\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 03. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know from the above results,  the columns \"season\",\"holiday\",\"workingday\" and \"weather\" should be of \"categorical\" data type. But the current data type is \"int\" for those columns. We will transform the dataset to get started up with EDA.\n",
    "\n",
    "- Create new columns \"date, \"year\", \"month\", \"day\", \"hour\", \"weekday\" from \"datetime\" column.\n",
    "- Coerce the datatype of \"season\", \"holiday\", \"workingday\" and \"weather\" to category.\n",
    "- Drop the datetime column as we already extracted useful features from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_train = train_data.copy()\n",
    "print(temp_train.head())\n",
    "temp_train.info()   # DataFrame information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'datatime' data processing for Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create new columns \"date, \"year\", \"month\", \"day\", \"hour\" from \"datetime\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# runnung time test\n",
    "start_time = time.time()\n",
    "\n",
    "temp_train['date'] = pd.to_datetime(temp_train['datetime'])\n",
    "temp_train['year'] = temp_train['date'].dt.year\n",
    "temp_train['month'] = temp_train['date'].dt.month\n",
    "temp_train['day'] = temp_train['date'].dt.day\n",
    "temp_train['hour'] = temp_train['date'].dt.hour\n",
    "\n",
    "end_time = time.time()\n",
    "lambda_ctime = end_time - start_time\n",
    "\n",
    "print(\"실행 시간 : \", np.round(lambda_ctime, 4))\n",
    "print(temp_train[['datetime', 'year', 'month', 'day', 'hour']])\n",
    "temp_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the column 'weekday'\n",
    "    + we can create the column that represents the name of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_train['weekday'] = temp_train['date'].dt.day_name()\n",
    "temp_train['weekday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the number values of the column 'weekday' into the character values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_train['season'] = temp_train['season'].map({\n",
    "    1 : 'Spring',\n",
    "    2 : 'Summer',\n",
    "    3 : 'Fall',\n",
    "    4 : 'Winter'\n",
    "})\n",
    "temp_train['season']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the number values of the column 'weather' into the character values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_train['weather'] = temp_train['weather'].map({\n",
    "    1 : 'Clear',\n",
    "    2 : 'Few Clouds',\n",
    "    3 : 'Light snow, Rain',\n",
    "    4 : 'Heavy snow, Rain'\n",
    "})\n",
    "temp_train['weather']\n",
    "\n",
    "print(temp_train.info())\n",
    "temp_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Once we get hang of the data and columns, we geneally have a step to find out whether we have any missing values in our data. Luckily we dont have any missing value in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 04. Exploratory Data Analysis\n",
    "It is a competition to predict figures. To predict the figures well, We need to visualize the data to figure out which columns to delete. We need to visualize the train data corresponding to the dependent variable, and we need to check the distribution to consider whether to give the log transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the difference between 'Normal Graph' and 'Log Transformed Graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 10))\n",
    "\n",
    "sns.histplot(train_data['count'], ax = ax[0])\n",
    "sns.histplot(np.log1p(train_data['count']), ax = ax[1])  # Log conversion\n",
    "\n",
    "# title option\n",
    "ax[0].set_title('Normal Graph')\n",
    "ax[1].set_title('Log Transformed Graph')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The graph of Rental amounts by 'year', 'month', 'day', 'hour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 2, ncols = 2)\n",
    "\n",
    "# step 1. Basic setting of the entire graph\n",
    "## Spacing Between Graphs\n",
    "fig.tight_layout()\n",
    "\n",
    "## Manage overall graph size\n",
    "fig.set_size_inches(15,12)\n",
    "\n",
    "# step 2. Enter each individual graph\n",
    "sns.boxplot(x = 'year', y = 'count', hue = 'season', \n",
    "            data = temp_train,\n",
    "            palette = \"Set2\",\n",
    "           ax = ax[0, 0])\n",
    "sns.boxplot(x = 'month', y = 'count', data = temp_train, ax = ax[0, 1])\n",
    "sns.barplot(x = 'day', y = 'count', data = temp_train,\n",
    "            palette = \"flare\", ax = ax[1, 0], capsize = .005)\n",
    "sns.boxplot(x = 'hour', y = 'count', data = temp_train, ax = ax[1,1])\n",
    "\n",
    "# step 3. Insert detailed options\n",
    "ax[0, 0].set(xlabel = 'The Years : 2011 / 2012', ylabel = 'Count', title = 'Box Plot on Count By Year')\n",
    "ax[0, 1].set(xlabel = 'Month', ylabel = 'Count', title = 'Box Plot on Count By Month')\n",
    "ax[1, 0].set(xlabel = 'Day', ylabel = 'Count', title = 'Bar Plot on Count By Day')\n",
    "ax[1, 1].set(xlabel = 'Hour Of The Day', ylabel = 'Count', title = 'Box Plot on Count By Hour Of The Day')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The graph of Rental amounts by 'season', 'weather', 'holiday', 'workingday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_train['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 2, ncols = 2)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(15,12)\n",
    "\n",
    "sns.boxplot(x = 'season', y = 'count', data = temp_train, ax = ax[0, 0], palette = \"husl\")\n",
    "sns.boxplot(x = 'weather', y = 'count', data = temp_train, ax = ax[0, 1], palette = \"pastel\")\n",
    "sns.boxplot(x = 'holiday', y = 'count', data = temp_train, ax = ax[1, 0])\n",
    "sns.boxplot(x = 'workingday', y = 'count', data = temp_train, ax = ax[1,1], palette = \"Set2\")\n",
    "\n",
    "ax[0, 0].set(xlabel = 'Season', ylabel = 'Count', title = 'Box Plot on Count By Season')\n",
    "ax[0, 1].set(xlabel = 'Weather', ylabel = 'Count', title = 'Box Plot on Count By Weather')\n",
    "ax[1, 0].set(xlabel = 'Holiday', ylabel = 'Count', title = 'Box Plot on Count By Holiday')\n",
    "ax[1, 1].set(xlabel = 'Workingday', ylabel = 'Count', title = 'Box Plot on Count By Workingday')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the 'season' column and the 'month' column show similar shapes on the graph, we decided to remove the 'month' column.\n",
    "- Also, The 'day' columns are harder to obtain analytical insights than other columns, so delete day columns as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The graph of Rental amounts by 'hour' based on various variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 5)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(15,30)\n",
    "\n",
    "sns.pointplot(x = 'hour', y = 'count', hue = 'workingday', data = temp_train, ax = ax[0], palette = 'hls')\n",
    "sns.pointplot(x = 'hour', y = 'count', hue = 'holiday', data = temp_train, ax = ax[1], palette = \"icefire\")\n",
    "sns.pointplot(x = 'hour', y = 'count', hue = 'weekday',  data = temp_train, ax = ax[2], palette = \"colorblind\")\n",
    "sns.pointplot(x = 'hour', y = 'count', hue = 'season', data = temp_train, ax = ax[3], palette = 'Paired')\n",
    "sns.pointplot(x = 'hour', y = 'count', hue = 'weather', data = temp_train, ax = ax[4], palette = 'rocket' )\n",
    "\n",
    "ax[0].set(xlabel = 'Hour', ylabel = 'Count', title = 'Point Polt on Count By Workingday Hour')\n",
    "ax[1].set(xlabel = 'Hour', ylabel = 'Count', title = 'Point Polt on Count By Holiday Hour')\n",
    "ax[2].set(xlabel = 'Hour', ylabel = 'Count', title = 'Point Polt on Count By Weekday Hour')\n",
    "ax[3].set(xlabel = 'Hour', ylabel = 'Count', title = 'Point Polt on Count By Season Hour')\n",
    "ax[4].set(xlabel = 'Hour', ylabel = 'Count', title = 'Point Polt on Count By Weather Hour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check values of the column 'weather'\n",
    "    + When you look at the weather graph, something seems strange. Let's check the frequency of the weather column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(temp_train['weather'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'Heavy snow, Rain' value has one frequency \n",
    "    + Let's extract and examine the row corresponding to The 'Heavy snow, Rain' value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_train.loc[temp_train['weather'] == 'Heavy snow, Rain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since there is only one frequency of Heavy snow and Rain, it seems meaningless to predict Heavy snow and Rain in the test dataset. Therefore, it seems better to delete the 'Heavy snow, Rain' value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot with regression lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 2, ncols = 2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.set_size_inches(12, 18)\n",
    "\n",
    "sns.regplot(x = 'temp', y = 'count', data = temp_train, \n",
    "            scatter_kws = {'alpha' : 0.3, 'color' : '#3EFA66'},\n",
    "            line_kws = {'color' : '#FC28D7'}, ax = ax[0, 0])\n",
    "sns.regplot(x = 'atemp', y = 'count', data = temp_train, \n",
    "            scatter_kws = {'alpha' : 0.3, 'color' : '#E69130'},\n",
    "            line_kws = {'color' : '#717AFF'}, ax = ax[0, 1])\n",
    "sns.regplot(x = 'humidity', y = 'count', data = temp_train, \n",
    "            scatter_kws = {'alpha' : 0.3, 'color' : '#D16A4D'},\n",
    "            line_kws = {'color' : '#6BE6D9'}, ax = ax[1, 0])\n",
    "sns.regplot(x = 'windspeed', y = 'count', data = temp_train, \n",
    "            scatter_kws = {'alpha' : 0.3, 'color' : '#7A6CE6'},\n",
    "            line_kws = {'color' : '#FC28D7'}, ax = ax[1, 1])\n",
    "\n",
    "ax[0, 0].set(xlabel = 'Temp', ylabel = 'Count', title = 'Rental amounts by Temp')\n",
    "ax[0, 1].set(xlabel = 'aTemp', ylabel = 'Count', title = 'Rental amounts by aTemp')\n",
    "ax[1, 0].set(xlabel = 'Humidity', ylabel = 'Count', title = 'Rental amounts by Humidity')\n",
    "ax[1, 1].set(xlabel = 'Windspeed', ylabel = 'Count', title = 'Rental amounts by Windspeed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there's something weird in the 'windspeed' column\n",
    "    + there are many '0' values in the 'windspeed' column  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_train['windspeed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We cannot know exactly what 0 means among the values in the 'windspeed' column.\n",
    "    + Therefore, we drop the 'windspeed' column to avoid confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Heatmap Graph\n",
    "- Correlation coefficient analysis\n",
    "    + The figure is positive : a positive relationship\n",
    "    + The figure is negative : a negative relationship\n",
    "    + 0 ~ ±0.2 : There is no correlation between the two variables.\n",
    "    + ±0.2 ~ ±1 : The larger the value, the greater the correlation between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CorrMat = temp_train[['temp','atemp', 'humidity', 'windspeed','count']].corr()\n",
    "CorrMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.heatmap(CorrMat, annot = True)\n",
    "# Check the correlation ratio between count column and other Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05. Data Preprocessing\n",
    "- step 01. Drop the 'casual', 'registered' columns from the train_data\n",
    "- step 02. Drop data with a value of 4 in the weather column & Data combine\n",
    "- step 03. 'Datetime' data processing(including dropping 'month', 'day' columns)\n",
    "- step 04. The 'season', 'weather' columns processing\n",
    "    + convert 'numeric' into 'character'  \n",
    "- step 05. Drop the 'windspeed' column\n",
    "- step 06. Drop the 'datetime', 'date' columns\n",
    "- step 07. Encoding all characters to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 01. Drop the 'casual', 'registered' columns from the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['casual', 'registered'], axis = 1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 02. Drop data with a value of 4 in the weather column & Data combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop data with a value of 4 in the weather column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['weather'] != 4].reset_index(drop = True)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine Train And Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_data, test_data]).reset_index(drop = True)\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 03. 'Datetime' data processing(including dropping 'month', 'day' columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data['date'] = pd.to_datetime(all_data['datetime'])\n",
    "all_data['year'] = all_data['date'].dt.year\n",
    "all_data['hour'] = all_data['date'].dt.hour\n",
    "all_data['weekday'] = all_data['date'].dt.day_name()\n",
    "\n",
    "all_data.shape\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 04. The 'season',  'weather' columns processing (convert 'numeric' into 'character')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'season' column processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data['season'] = all_data['season'].replace(to_replace = [1, 2, 3, 4],\n",
    "                                               value = ['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "print(all_data['season'])\n",
    "\n",
    "all_data.shape\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'weather' column processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data['weather'] = all_data['weather'].map({\n",
    "    1 : 'Clear',\n",
    "    2 : 'Few Cloud',\n",
    "    3 : 'Light rain, snow',\n",
    "    4 : 'Heavy rain, snow'\n",
    "})\n",
    "\n",
    "all_data['weather']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 05. Drop the 'windspeed' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = all_data.drop(['windspeed'], axis = 1)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 06. Drop the 'datetime', 'date' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = all_data.drop(['datetime', 'date'], axis = 1)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 07. Encoding all characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data).reset_index(drop = True)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 06. Dividing dataset\n",
    "- Re-separation into train_data and test_data\n",
    "- 'count' : target data(Dependent variable)\n",
    "    + train_data if target data is present\n",
    "    + test_data if target data isn't present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = all_data[~pd.isnull(all_data['count'])]\n",
    "test_data = all_data[pd.isnull(all_data['count'])]\n",
    "# train_data if Null isn't in 'count' column\n",
    "# test_data if Null is in 'count' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = train_data['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop the 'count' column from train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train_data.drop(['count'], axis = 1)\n",
    "test_data = test_data.drop(['count'], axis = 1)\n",
    "\n",
    "X.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the data 'X', 'y', 'test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 07. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSLE Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmsle(y_act, y_pred, convertExp = True):\n",
    "    if convertExp:\n",
    "# convertExp is a parameter that determines whether to exponentially convert input data.\n",
    "        y_act = np.exp(y_act),\n",
    "        y_pred = np.exp(y_pred)\n",
    "    log1 = np.nan_to_num(np.array([np.log(z + 1) for z in y_act]))\n",
    "    log2 = np.nan_to_num(np.array([np.log(z + 1) for z in y_pred]))\n",
    "    calc = (log1 - log2) ** 2\n",
    "    return np.sqrt(np.mean(calc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data 'X', 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "lr_model.fit(X_train, log_y_train)\n",
    "\n",
    "# Model Prediction\n",
    "lr_preds = lr_model.predict(X)\n",
    "print(\"RMSLE Value For Linear Regression: \", rmsle(np.exp(log_y), np.exp(lr_preds), False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression RMSLE score\n",
    "    + y_train : 1.0091\n",
    "    + y_test : 1.0128\n",
    "    + y : 1.0102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Models - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators = 100)\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "rf_model.fit(X_train, log_y_train)\n",
    "\n",
    "# Model Prediction\n",
    "rf_preds = rf_model.predict(X)\n",
    "print(\"RMSLE Value For Random Forest: \", rmsle(np.exp(log_y), np.exp(rf_preds), False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest RMSLE score\n",
    "    + y_train : 0.1182\n",
    "    + y_test : 0.3191\n",
    "    + y : 0.2001\n",
    "    \n",
    "    \n",
    "- Overfitted to (X_train, y_train) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model - Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_model = GradientBoostingRegressor(n_estimators = 5000, alpha = 0.01);\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "gb_model.fit(X_train, log_y_train)\n",
    "\n",
    "# Model Prediction\n",
    "gb_preds = gb_model.predict(X)\n",
    "print(\"RMSLE Value For Gradient Boost: \", rmsle(np.exp(log_y), np.exp(gb_preds), False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boost RMSLE score\n",
    "    + y_train : 0.2008\n",
    "    + y_test : 0.3103\n",
    "    + y : 0.2356\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators = 100,\n",
    "                          max_depth = 5,\n",
    "                          learning_rate = 0.1,\n",
    "                          random_state = 42,\n",
    "                          eval_metric = 'rmsle')\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "w_list = [(X_train, log_y_train), (X_test, log_y_test)]\n",
    "\n",
    "xgb_model.fit(X_train, log_y_train, eval_set = w_list)\n",
    "\n",
    "# Model Prediction\n",
    "xgb_preds = xgb_model.predict(X)\n",
    "print(\"RMSLE Value For XGBoost: \", rmsle(np.exp(log_y), np.exp(xgb_preds), False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost RMLSE score\n",
    "    + y_train : 0.2607\n",
    "    + y_test : 0.3077\n",
    "    + y : 0.2757"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function (Based on RMSE scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def cv_rmse(model, n_folds=5):\n",
    "    cv = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "    rmse_list = np.sqrt(-cross_val_score(model, X, log_y, scoring='neg_mean_squared_error', cv=cv))\n",
    "    print('CV RMSE value list:', np.round(rmse_list, 4))\n",
    "    print('CV RMSE mean value:', np.round(np.mean(rmse_list), 4))\n",
    "    return (rmse_list)\n",
    "\n",
    "n_folds = 5\n",
    "rmse_scores = {}\n",
    "# lr_model = LinearRegression()\n",
    "xgb_model =  XGBRegressor()\n",
    "\n",
    "score = cv_rmse(xgb_model, n_folds)\n",
    "print(\"XGBoost - mean: {:.4f} (std: {:.4f})\".format(score.mean(), score.std()))\n",
    "rmse_scores['XGBoost'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross-validation rmse_scores\n",
    "    + Linear Regression : 1.0647\n",
    "    + RandomForest : 0.3422\n",
    "    + GradientBoosting : 0.4369\n",
    "    + XGBoost : 0.3290\n",
    "    + LightGBM : Error -> [LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
    "\n",
    "\n",
    "- As a result of model evaluation and cross-validation, xgboost with the best performance is selected as the final prediction model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for best prediction score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators = 200,\n",
    "                          max_depth = 8,\n",
    "                          learning_rate = 0.1,\n",
    "                          random_state = 42,\n",
    "                          eval_metric = 'rmsle')\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "w_list = [(X_train, log_y_train), (X_test, log_y_test)]\n",
    "\n",
    "xgb_model.fit(X_train, log_y_train, eval_set = w_list)\n",
    "\n",
    "# Model Prediction\n",
    "xgb_preds = xgb_model.predict(X)\n",
    "print(\"RMSLE Value For XGBoost: \", rmsle(np.exp(log_y), np.exp(xgb_preds), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators = 60,\n",
    "                          max_depth = 10,\n",
    "                          learning_rate = 0.1,\n",
    "                          random_state = 42,\n",
    "                          eval_metric = 'rmsle')\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "w_list = [(X_train, log_y_train), (X_test, log_y_test)]\n",
    "\n",
    "xgb_model.fit(X_train, log_y_train, eval_set = w_list)\n",
    "\n",
    "# Model Prediction\n",
    "xgb_preds = xgb_model.predict(X)\n",
    "print(\"RMSLE Value For XGBoost: \", rmsle(np.exp(log_y), np.exp(xgb_preds), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators = 80,\n",
    "                          max_depth = 10,\n",
    "                          learning_rate = 0.1,\n",
    "                          random_state = 42,\n",
    "                          eval_metric = 'rmsle')\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "w_list = [(X_train, log_y_train), (X_test, log_y_test)]\n",
    "\n",
    "xgb_model.fit(X_train, log_y_train, eval_set = w_list)\n",
    "\n",
    "# Model Prediction\n",
    "xgb_preds = xgb_model.predict(X)\n",
    "print(\"RMSLE Value For XGBoost: \", rmsle(np.exp(log_y), np.exp(xgb_preds), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators = 80,\n",
    "                          max_depth = 7,\n",
    "                          learning_rate = 0.1,\n",
    "                          random_state = 42,\n",
    "                          eval_metric = 'rmsle')\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "w_list = [(X_train, log_y_train), (X_test, log_y_test)]\n",
    "\n",
    "xgb_model.fit(X_train, log_y_train, eval_set = w_list)\n",
    "\n",
    "# Model Prediction\n",
    "xgb_preds = xgb_model.predict(X)\n",
    "print(\"RMSLE Value For XGBoost: \", rmsle(np.exp(log_y), np.exp(xgb_preds), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators = 80,\n",
    "                          max_depth = 7,\n",
    "                          learning_rate = 0.1,\n",
    "                          random_state = 42,\n",
    "                          eval_metric = 'rmsle')\n",
    "\n",
    "# Log conversion\n",
    "log_y = np.log(y)\n",
    "log_y_train = np.log(y_train)\n",
    "log_y_test = np.log(y_test)\n",
    "w_list = [(X_train, log_y_train), (X_test, log_y_test)]\n",
    "\n",
    "xgb_model.fit(X_train, log_y_train, eval_set = w_list)\n",
    "\n",
    "# Model Prediction\n",
    "xgb_preds = xgb_model.predict(test_data)\n",
    "xgb_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 08. Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exponential conversion\n",
    "final_preds = np.exp(xgb_preds)\n",
    "final_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 09. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_data['count'] = final_preds\n",
    "submission_data.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
